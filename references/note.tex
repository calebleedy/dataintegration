\documentclass[12pt]{article}

\usepackage{amsmath, amssymb, mathrsfs, fancyhdr}
\usepackage{syntonly, lastpage, hyperref, enumitem, graphicx}
\usepackage{biblatex}
\usepackage{booktabs}
\usepackage{float}

\addbibresource{references.bib}

\hypersetup{colorlinks = true, urlcolor = black}

\headheight     15pt
\topmargin      -1.5cm   % read Lamport p.163
\oddsidemargin  -0.04cm  % read Lamport p.163
\evensidemargin -0.04cm  % same as oddsidemargin but for left-hand pages
\textwidth      16.59cm
\textheight     23.94cm
\parskip         7.2pt   % sets spacing between paragraphs
\parindent         0pt   % sets leading space for paragraphs
\pagestyle{empty}        % Uncomment if don't want page numbers
\pagestyle{fancyplain}

\newcommand{\MAP}{{\text{MAP}}}
\newcommand{\argmax}{{\text{argmax}}}
\newcommand{\argmin}{{\text{argmin}}}
\newcommand{\Cov}{{\text{Cov}}}
\newcommand{\Var}{{\text{Var}}}
\newcommand{\logistic}{{\text{logistic}}}

\begin{document}

%\lhead{Caleb Leedy}
\title{A note on optimal estimation under non-monotone missingness by design }
\author{Jae-Kwang Kim}
%\chead{STAT 615 - Advanced Bayesian Methods}
%\rhead{Page \thepage\ of \pageref{LastPage}}
%\rhead{April 4, 2023}
\maketitle 


\begin{itemize}
%\item The sample $A$ is partitioned as $A= A_{11} \cup A_{10} \cup A_{01} \cup A_{00}$. 



\item Define 
$$ \delta_{i1} =
\left\{ \begin{array}{ll}
 1 & \mbox{ if } Y_{1i} \mbox{ is observed} \\
 0 & \mbox{ otherwise}
\end{array}
\right. 
$$
and, similarly, we can define 
$\delta_{2i} $. 


\item We  define $A_{01}= \{ i ; \delta_{1i} =0 \mbox{ and } \delta_{2i}=1\}$. 


\item We are interested in estimating $\theta=E(Y_2)$. Note that, if we ignore $A_2$, 
then the missingness pattern is monotone and the following three-phase regression estimator can be used. 
$$
\hat{\theta}_1 = \frac{1}{n} \sum_{i=1}^n g_1^* (x_i) + \frac{1}{n} \sum_{i=1}^n \frac{\delta_{1i}}{ \pi_{1i}} \left\{ g_2^* (x_i, y_{1i}) - g_1^*(x_i) \right\} + \frac{1}{n} \sum_{i=1}^n \frac{\delta_{1i} \delta_{2i} }{ \pi_{12i}} \left\{ y_{2i} - g_2^*(x_i, y_i) \right\} $$
where 
$ g_1^*(x)= E(Y_2 \mid x)$ and $g_2^*(x,y_1) = E(Y_2 \mid x, y_1)$. 

\item Now, to incorporate the information in $A_{01}$, we consider the following two-phase regression estimator 
$$
\hat{\theta}_2 = \frac{1}{n} \sum_{i=1}^n g_1^* (x_i) + \frac{1}{n} \sum_{i=1}^n \frac{(1-\delta_{1i} )\delta_{2i} }{ \pi_{2i} -\pi_{12i}} \left\{ y_{2i} - g_1^*(x_i) \right\} $$


\item The two estimators are both unbiased. We can consider 
$$ \hat{\theta}_\alpha = \alpha \hat{\theta}_1 + (1- \alpha) \hat{\theta}_2 $$
and obtain the optimal choice of $\alpha$ that minimizes the variance.
\item Please check Section 11.4 of the sampling book that I wrote. 
\end{itemize}

\end{document}

