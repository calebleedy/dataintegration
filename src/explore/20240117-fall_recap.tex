\documentclass[12pt]{article}

\usepackage{amsmath, amssymb, mathrsfs, fancyhdr}
\usepackage{syntonly, lastpage, hyperref, enumitem, graphicx}
\usepackage{biblatex}
\usepackage{booktabs}
\usepackage{float}

\addbibresource{references.bib}

\hypersetup{colorlinks = true, urlcolor = black}

\headheight     15pt
\topmargin      -1.5cm   % read Lamport p.163
\oddsidemargin  -0.04cm  % read Lamport p.163
\evensidemargin -0.04cm  % same as oddsidemargin but for left-hand pages
\textwidth      16.59cm
\textheight     23.94cm
\parskip         7.2pt   % sets spacing between paragraphs
\parindent         0pt   % sets leading space for paragraphs
\pagestyle{empty}        % Uncomment if don't want page numbers
\pagestyle{fancyplain}

\newcommand{\MAP}{{\text{MAP}}}
\newcommand{\argmax}{{\text{argmax}}}
\newcommand{\argmin}{{\text{argmin}}}
\newcommand{\Cov}{{\text{Cov}}}
\newcommand{\Var}{{\text{Var}}}
\newcommand{\logistic}{{\text{logistic}}}

\renewcommand{\arraystretch}{1.2}

\begin{document}

\lhead{Caleb Leedy}
\chead{Non-monotone Missingness}
%\chead{STAT 615 - Advanced Bayesian Methods}
%\rhead{Page \thepage\ of \pageref{LastPage}}
\rhead{\today}

\section*{Recap of Fall 2023}

Fall 2023 started with the goal of showing that $\hat \theta_{prop}$ in
Equation~\ref{eq:prop} is (or is not) an optimal estimator.

\begin{align}
  \hat \theta_{prop} &= \label{eq:prop}\\ \nonumber
  &n^{-1} \sum_{i = 1}^n E[g_i \mid X_i] + n^{-1} \sum_{i = 1}^n
  \frac{\delta_{1+}}{\pi_{1+}} (E[g_i \mid X_i, Y_{1i}] - E[g_i \mid X_i]) \\
  \nonumber
  &+ n^{-1} \sum_{i = 1}^n \frac{\delta_{2+}}{\pi_{2+}} (E[g_i \mid X_i,
  Y_{2i}] - E[g_i \mid X_i]) \\ \nonumber
  &+ n^{-1} \sum_{i = 1}^n \frac{\delta_{11}}{\pi_{11}} (g_i - E[g_i \mid X_i,
  Y_{1i}] - E[g_i \mid X_i, Y_{2i}] + E[g_i \mid X_i]). \nonumber
\end{align}

While this estimator performs quite well overall, it is outperformed by 
$\hat \theta_\delta$ (see Table~\ref{tab:ests}) in a simulation where the 
number of observations in segments $A_{10}$ differed from $A_{01}$. Studying 
this estimator led to the creation of a class of estimators in
Equation~\ref{eq:class} with specific examples in Table~\ref{tab:ests}.

\begin{equation}\label{eq:class}
\hat \theta = \frac{\delta_{11}}{\pi_{11}}g(Z) + \beta_0(\delta, c_0)E[g(Z)
\mid X] + \beta_1(\delta, c_1)E[g(Z) \mid X, Y_1] + \beta_2(\delta, c_2) E[g(Z)
\mid X, Y_2].
\end{equation}

\begin{table}[ht!]
  \centering
  \caption{Specific examples of estimators from the larger class in
  Equation~\ref{eq:class}.}
  \label{tab:ests}
\begin{tabular}{lrrr}
  \toprule
  Estimator & $\beta_0(\delta, c_0)$ & $\beta_1(\delta, c_1)$ & Implemented \\
  \midrule
  $\hat \theta_{prop}$ & $\left(1 - \frac{(\delta_{10} + \delta_{11})}{(\pi_{10} + \pi_{11})} - 
  \frac{(\delta_{01} + \delta_{11})}{(\pi_{01} + \pi_{11})} + \frac{\delta_{11}}{\pi_{11}}\right)$ &
  $\left(\frac{\delta_{10} + \delta_{11}}{\pi_{10} + \pi_{11}} - \frac{\delta_{11}}{\pi_{11}}\right)$ & \checkmark \\
  $\hat \theta^{ind}_{prop}$ & $\left(1 - \frac{(\delta_{10})}{(\pi_{10})} - 
  \frac{(\delta_{01})}{(\pi_{01})} + \frac{\delta_{11}}{\pi_{11}}\right)$ &
  $\left(\frac{\delta_{10}}{\pi_{10}} - \frac{\delta_{11}}{\pi_{11}}\right)$ & \checkmark \\
  $\hat \theta_{c}$ & $c_0\left(1 - \frac{(\delta_{10} + \delta_{11})}{(\pi_{10} + \pi_{11})} - 
  \frac{(\delta_{01} + \delta_{11})}{(\pi_{01} + \pi_{11})} + \frac{\delta_{11}}{\pi_{11}}\right)$ &
  $c_1\left(\frac{\delta_{10} + \delta_{11}}{\pi_{10} + \pi_{11}} - \frac{\delta_{11}}{\pi_{11}}\right)$ & \checkmark \\
  $\hat \theta_{c, ind}$ & $c_0\left(1 - \frac{(\delta_{10})}{(\pi_{10})} - 
  \frac{(\delta_{01})}{(\pi_{01})} + \frac{\delta_{11}}{\pi_{11}}\right)$ &
  $c_1\left(\frac{\delta_{10}}{\pi_{10}} - \frac{\delta_{11}}{\pi_{11}}\right)$ & \checkmark \\
  $\hat \theta_{\delta}$ & $c_0\left(\frac{\delta_{11}}{\pi_{11}} - \frac{\delta_{00}}{\pi_{00}}\right)$ &
  $c_1\left(\frac{\delta_{11}}{\pi_{11}} - \frac{\delta_{10}}{\pi_{10}}\right)$ & \checkmark \\
  \bottomrule
\end{tabular}
\end{table}

The challenge with working with this class is the $\beta$ coefficients. These
are functional coefficients and so it is difficult for me to understand how to 
show that a particular class is optimal. Dispite this difficulty, we were able 
to show that the proposed estimator is not optimal via simulation. When this 
estimator was compared to other estimators in Table~\ref{eq:class}, it did not 
perform the best when the segments were unbalanced and the estimating function 
was nonlinear. This is shown in Table~\ref{tab:unbalanced}

\begin{table}[ht!]
  \caption{True Values: $\theta = 10$, $\rho = 0.5$. This simulation assesses 
  the bias and standard deviation (SD) of different estimators of the function 
$\theta = E[Y_1^2 Y_2]$ where $Y_1 = x + \varepsilon_1$, $Y_2 = \beta + x + 
\varepsilon_2$, $x \perp (\varepsilon_1, \varepsilon_2)$, and 
$(\varepsilon_1, \varepsilon_2)$ come from a mean zero bivariate normal 
distribution with unit variance and covariance of $\rho$. This simulation uses 
a sample size of $N = 1000$ and $B = 3000$ Monte Carlo simulations. Each 
observation has the following independent probabilities of landing into a 
respective segment: $\pi_{11} = 0.2$, $\pi_{10} = 0.4$, $\pi_{01} = 0.1$, and
$\pi_{00} = 0.3$. The columns of Tstat and P-value give the test statistic and
p-value from a two sample test for unbiasedness.}
  \label{tab:unbalanced}
  \centering
  \begin{tabular}[t]{lrrrr}
    \toprule
    Algorithm & Bias & SD & Tstat & P-value\\
    \midrule
    Oracle & 0.007 & 0.529 & 0.741 & 0.229\\
    CC & 0.036 & 1.190 & 1.667 & 0.048\\
    IPW & 0.029 & 1.372 & 1.170 & 0.121\\
    $\hat \theta_{prop}$ & 0.004 & 0.694 & 0.292 & 0.385\\
    $\hat \theta_{c}$ & 0.007 & 0.670 & 0.582 & 0.280\\
    $\hat \theta_{\delta}$ & 0.018 & 0.675 & 1.478 & 0.070\\
    \bottomrule
  \end{tabular}
\end{table}

\section*{Current Work}

As discussed in a related note, we are currently trying to understand the 
loss of efficiency of using a semiparametric estimator with the model is 
correctly specified. I am having difficulties with the current simulation 
setup but this work is contained in \verb|efficiencyloss_semi.tex|.

\section*{Potential Ideas to Pursue}

\begin{itemize}
  \item Tsiatis (2006) describes a recursive method to get the optimal 
    semiparametric estimator for non-monotone data. This is difficult and 
    confusing. However, we can pose the estimation as the solution to an 
    integral equation. While people know that one can do this, it has not 
    been done. The real work would be estimating the variance.
  \item Often in simulations, the optimal value for $c_i$ would be $1$ or 
    $-1$. Since the optimal semiparametric estimator is a double projection
    (see Chapter 10 of Tsiatis (2006)), I hypothesis that it may be possible to
    construct a test to see how close to the optimal we are by projecting 
    the the $\beta$ coefficients onto some contants $c$.
\end{itemize}


\end{document}
