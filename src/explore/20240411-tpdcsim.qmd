---
title: "Two Phase Debiased Calibration Simulation"
author: "Caleb Leedy"
from: markdown+emoji
format: 
  html:
    embed-resources: true
    code-fold: true
    grid:
      margin-width: 450px
bibliography: references.bib
reference-location: margin
comments:
  hypothesis: true
---

# Summary

NOTE: The results in this report are depricated. An updated version of two-phase
debiased calibration is found in `proto-dctp.R`.

This report simulates two-phase sampling with the debiased calibration of
@kwon2024debiased. We check for the following:

1. Bias of $\hat Y$ and,
2. Bias of $\hat V(\hat Y)$.

For the estimator $\hat Y$ we construct 

1. The $\pi^*$-estimator,
2. The two-phase regression estimator,
3. The debiased calibration estimator (with known finite population total), and
4. The debiased calibration estimator with estimated population totals from the
   Phase 1 sample.

# Simulation Setup

```{r}
#| label: setup

B_sims <- 1000

N_obs <- 10000
n1_obs <- 1000
n2_obs <- 500

library(dplyr)
library(GECal)
library(nleqslv)
library(doParallel)
library(doRNG)
library(CVXR)

# source("GEcalib_code.R")

```

We have the following superpopulation model:

$$
\begin{aligned}
X_{1i} &\stackrel{ind}{\sim} N(2, 1) \\
X_{2i} &\stackrel{ind}{\sim} Unif(0, 4) \\
X_{3i} &\stackrel{ind}{\sim} N(0, 1) \\
X_{4i} &\stackrel{ind}{\sim} Unif(0.1, 0.9) \\
\varepsilon_i &\stackrel{ind}{\sim} N(0, 1) \\
Y_{i} &= 3 X_{1i} + 2 X_{2i} + \varepsilon_i \\
\pi_{1i} &= \Phi(-x_{3i} - 2)\\
\pi_{2i|1} &= x_{4i}.
\end{aligned}
$$

and the two-phase sampling scheme is to select a SRS of size $n = $`{r} n1_obs`
from a finite population of size $N = $`{r} N_obs` for the Phase 1 sample and a
SRS of size $r =$`{r} n2_obs` from the Phase 1 sample of size 
$n = $`{r} n1_obs`.

```{r}
#| label: gen data

gen_pop <- function(obs) {
  x1 <- rnorm(obs, 2, 1)
  x2 <- runif(obs, 0, 4)
  x3 <- rnorm(obs, 0, 1)
  x4 <- runif(obs, 0.1, 0.9)
  eps <- rnorm(obs)

  y <- 3 * x1 + 2 * x2 + eps

  return(tibble(X1 = x1, X2 = x2, X3 = x3, X4 = x4, Y = y))
}

gen_twophase <- function(pop_df, p1_obs, p2_obs) {

  # Phase 1 
  # Poisson sampling
  # mean(pi_i) = 0.1
  ptemp <- pt(-pop_df$X3 - 2, 3)
  pi_i <- ifelse(ptemp > 0.7, 0.7, ptemp)
  del1 <- rbinom(nrow(pop_df), 1, pi_i)
  p1_df <- pop_df %>%
    mutate(pi1 = pi_i) %>%
    mutate(del1 = del1) %>%
    filter(del1 == 1)

  # SRS
  # p1_ind <- sample(1:nrow(pop_df), size = p1_obs)
  # p1_df <- filter(pop_df, row_number() %in% p1_ind)

  # Phase 2
  # pi2_1 <- p1_df$X4
  p2tmp <- pt(-p1_df$X1 + 1, 3)
  pi2_i <- ifelse(p2tmp > 0.9, 0.9, p2tmp)
  del2 <- rbinom(nrow(p1_df), 1, pi2_i)

  p1_df <- mutate(p1_df, pi2 = pi2_i)

  p2_df <- p1_df %>%
    mutate(del2 = del2) %>%
    filter(del2 == 1)

  # SRS
  # p2_ind <- sample(1:nrow(p1_df), size = p2_obs)
  # p2_df <- filter(p1_df, row_number() %in% p2_ind)

  return(list(P1 = p1_df, P2 = p2_df))

}

```


```{r}
#| label: estimators

solveEL_prim <- function(xmat, d, xtot) {
  w_vec <- Variable(nrow(xmat))
  obj <- Maximize(sum(d * log(w_vec)))
  constr <- list(t(xmat) %*% w_vec - xtot == 0)
  prob <- Problem(obj, constr)
  prim <- solve(prob)
  resp <- prim$getValue(w_vec)
  return(drop(resp))
}

# resw = resp
# gbar = sum(-log(resw), na.rm = TRUE)
# toremove <- which(is.na(log(resw)))
# zbar = colSums(xmat[-toremove, ])
# zbar = colSums(xmat)
# lam = drop((gbar %*% zbar) %*% MASS::ginv(t(t(zbar)) %*% t(zbar)))
# 
# f(lam, xmat, d, xtot)
# f(res$x, xmat, d, xtot)
# 
# res$x
# lam
# sum(p2_df$Y * resd) / pop_obs
# sum(p2_df$Y * resp) / pop_obs


solveEL <- function(xmat, d, xtot, acc2 = FALSE) {

  f <- function(lam, xmat, d, xtot, returnw = FALSE) {
    w <- -d / drop(xmat %*% lam)

    if (returnw) {
      return(w)
    } else {
      return(drop(w %*% xmat) - xtot)
    }
  }

  j <- function(lam, xmat, d, xtot) {
    t(xmat) %*% diag(d / drop(xmat %*% lam)^2) %*% xmat
  }

  init <- c(rep(0, ncol(xmat) - 1), 1)
  res <- 
  nleqslv(init, f, jac = j, xmat = xmat, d = d, xtot,
          method = "Newton", control = list(maxit = 1e5, allowSingular = TRUE))

  resw <- f(res$x, xmat, d, returnw = TRUE)

  if (!(res$termcd %in% c(1))) {

    return(NA)

    w_prim <- solveEL_prim(xmat, d, xtot)
    gbar = sum(-log(w_prim), na.rm = TRUE)
    if (any(is.na(log(w_prim)))) {
      toremove <- which(is.na(log(w_prim)))
      zbar = colSums(xmat[-toremove, ])
    } else {
      zbar = colSums(xmat)
    }
    init = drop((gbar %*% zbar) %*% MASS::ginv(t(t(zbar)) %*% t(zbar)))

    res2 <- 
    nleqslv(init, f, jac = j, xmat = xmat, d = d, xtot,
            method = "Newton", control = list(maxit = 1e5, allowSingular = TRUE))

    if (!(res2$termcd %in% c(1))) {
      return(NA)
    }

    resw <- f(res2$x, xmat, d, returnw = TRUE)

  }

  return(resw)

}

# Each estimator should return two outcomes:
# 1. Point estimate, and
# 2. Variance estimate.
pi_star <- function(p1_df, p2_df, pop_obs, ...) {
  extra <- list(...)

  theta <- sum(p2_df$Y / (p2_df$pi1 * p2_df$pi2)) / pop_obs

  # SRS Variance
  # vhat <- (1 / n2 - 1 / pop_obs) * var(p2_df$Y)

  # Poisson Variance
  pis <- p2_df$pi1 * p2_df$pi2
  vhat <- sum((1 / pis^2 - 1 / pis) * p2_df$Y^2) / pop_obs^2

  return(list(theta = theta, Var = vhat))
}

tp_reg <- function(p1_df, p2_df, pop_obs, ...) {
  extra <- list(...)

  # Step 1: Get beta
  mod <- lm(Y ~ X1 + X2, data = p2_df)

  # Step 2: Predict
  # SRS
  # theta <- mean(predict(mod, p1_df))
   
  # Poisson
  theta <- (sum(predict(mod, p1_df) / p1_df$pi1) + 
  sum(1 / (p2_df$pi1 * p2_df$pi2) * (p2_df$Y - predict(mod, p2_df)))) / pop_obs

  # Step 3: Get variance estimator
  # SRS
  # vhat <-
  #   (1 / n1 - 1 / pop_obs) * (mod$coefficients[2]^2 * var(p1_df$X1) + 
  #   mod$coefficients[3]^2 * var(p1_df$X2)) +
  #   (1 / n2 - 1 / n1) * var(p2_df$Y - predict(mod, p2_df))
   
  # Poisson
  p12_df <- 
    left_join(p1_df, p2_df, by = join_by(X1, X2, X3, Y, pi1, pi2, del1)) %>%
    mutate(del2 = ifelse(is.na(del2), 0, 1))
  pred_12 <- predict(mod, p12_df)
  eta <- pred_12 + p12_df$del2 / p12_df$pi2 * (p12_df$Y - pred_12)

  v1 <- sum((1 - p12_df$pi1) / p12_df$pi1^2 * eta^2)
  v2 <- sum(1 / (p2_df$pi1 * p2_df$pi2) * 
           (1 / p2_df$pi2 - 1) * (p2_df$Y - predict(mod, p2_df))^2)

  vhat <- (v1 + v2) / pop_obs^2

  return(list(theta = theta, Var = vhat))

}

dc_poptots <- function(p1_df, p2_df, pop_obs, ...) {
  extra <- list(...)

  if ("entropy" %in% names(extra)) {
    entropy <- extra$entropy
  } else {
    entropy <- "EL"
  }

  # TODO: I am not sure if d_vec is correct
  d_vec <- 1 / (p2_df$pi2 * p2_df$pi1)
  if (entropy == "EL") {
    gdi <- -1 / d_vec
    gpinv <- d_vec^2

  } else if (entropy == "ET") {
    gdi <- log(d_vec)
    gpinv <- d_vec

  } else {
    stop("This type of entropy has not yet been implemented.")
  }

  samp_X <- cbind(rep(1, nrow(p2_df)), as.matrix(select(p2_df, X1, X2)))

  # dc_w <-  
  #   GEcalib(cbind(samp_X, gdi),
  #           # d = rep(1, nrow(p2_df)),
  #           d = 1 / (p2_df$pi2),
  #           extra$pop_tot,
  #           entropy = entropy,
  #           DS = FALSE)

  dc_w_alt <- solveEL(cbind(samp_X, gdi), 1 / p2_df$pi2, extra$pop_tot)
  dc_w <- dc_w_alt

  # Mean Estimation
  theta <- sum(p2_df$Y * dc_w) / pop_obs

  # Variance Estimation

  Pi_dc <- diag(1 - 1 / d_vec) * (dc_w / pop_obs)^2
  z_dc <- model.matrix(~1 + p2_df$X1 + p2_df$X2 + gdi)
  gam_dc <- 
    solve(t(z_dc) %*% diag(gpinv) %*% z_dc, t(z_dc) %*% diag(gpinv) %*% p2_df$Y)
  vhat <- 
    (p2_df$Y - t(gam_dc) %*% t(z_dc)) %*% Pi_dc %*% t(p2_df$Y - t(gam_dc) %*% t(z_dc))

  return(list(theta = theta, Var = as.numeric(vhat)))
}

dc_esttots <- function(p1_df, p2_df, pop_obs, ...) {
  extra <- list(...)

  # Get estimates of population totals
  pop_est <- c(pop_obs,
               sum(p1_df$X1 / p1_df$pi1),
               sum(p1_df$X2 / p1_df$pi1),
               extra$pop_gdi)

  if ("entropy" %in% names(extra)) {
    entropy <- extra$entropy
  } else {
    entropy <- "EL"
  }

  if ("acc2" %in% names(extra)) {
    acc2 <- extra$acc2
  } else {
    acc2 <- FALSE
  }

  d_vec <- 1 / (p2_df$pi2 * p2_df$pi1)
  if (entropy == "EL") {
    gdi <- -1 / d_vec
    gpinv <- d_vec^2

  } else if (entropy == "ET") {
    gdi <- log(d_vec)
    gpinv <- d_vec

  } else {
    stop("This type of entropy has not yet been implemented.")
  }

  samp_X <- cbind(rep(1, nrow(p2_df)), as.matrix(select(p2_df, X1, X2)))

  dc_w_alt <- solveEL(cbind(samp_X, gdi), 1 / p2_df$pi2, pop_est, acc2)
  dc_w <- dc_w_alt

  if (any(is.na(dc_w))) {
    return(list(theta = NA, Var = NA))
  }

  # Mean Estimation
  theta <- sum(p2_df$Y * dc_w) / pop_obs

  # Variance Estimation
  # ex_var_mat <- matrix(nrow = 2, ncol = 2)
  # ex_var_mat[1, 1] <- sum((1 / p1_df$pi1^2 - 1 / p1_df$pi1) * p1_df$X1^2)
  # ex_var_mat[1, 2] <- sum((1 / p1_df$pi1^2 - 1 / p1_df$pi1) * p1_df$X1 * p1_df$X2)
  # ex_var_mat[2, 1] <- sum((1 / p1_df$pi1^2 - 1 / p1_df$pi1) * p1_df$X1 * p1_df$X2)
  # ex_var_mat[2, 2] <- sum((1 / p1_df$pi1^2 - 1 / p1_df$pi1) * p1_df$X2^2)

  # Pi_dc <- diag(1 - 1 / d_vec) * (dc_w / pop_obs)^2
  z_dc <- model.matrix(~1 + p2_df$X1 + p2_df$X2 + gdi)
  # gam_dc <- 
  #   solve(t(z_dc) %*% diag(gpinv) %*% z_dc, t(z_dc) %*% diag(gpinv) %*% p2_df$Y)
  # vhat <- 
  # (p2_df$Y - t(gam_dc) %*% t(z_dc)) %*% Pi_dc %*% t(p2_df$Y - t(gam_dc) %*% t(z_dc)) +
  # (gam_dc[2:3] %*% ex_var_mat %*% gam_dc[2:3] / pop_obs^2)

  phi_est <- 
    base::solve(t(z_dc) %*% diag(gpinv) %*% z_dc, t(z_dc) %*% (p2_df$Y * gpinv))

  p12_df <- 
    left_join(p1_df, p2_df, by = join_by(X1, X2, X3, X4, Y, pi1, pi2, del1)) %>%
    mutate(del2 = ifelse(is.na(del2), 0, 1))

  pred12 <- 
  model.matrix(~1 + p12_df$X1 + p12_df$X2 + I(-1/(p12_df$pi2 + p12_df$pi1))) %*%
    phi_est 

  model.matrix(~1 + p12_df$X1 + p12_df$X2 + I(-1/(p12_df$pi2 + p12_df$pi1))) %>%
    head
  pred2 <- 
  model.matrix(~1 + p2_df$X1 + p2_df$X2 + I(-1/(p2_df$pi2 + p2_df$pi1))) %*%
    phi_est
  eta <- pred12 + p12_df$del2 / p12_df$pi2 * (p12_df$Y - pred12)
  v1 <- sum((1 - p12_df$pi1) / p12_df$pi1^2 * eta^2)
  v2 <- sum(1 / (p2_df$pi1 * p2_df$pi2) * (1 / p2_df$pi2 - 1) * (p2_df$Y - pred2)^2)
  vhat <- (v1 + v2) / pop_obs^2

  return(list(theta = theta, Var = as.numeric(vhat)))
}

```

```{r}
#| label: MCMC

set.seed(1)
pop_df <- gen_pop(N_obs)
true_theta <- mean(pop_df$Y)

clust <- makeCluster(min(detectCores() - 2, 100))
registerDoParallel(clust)

mc_res <- foreach(iter=1:B_sims,
                  .packages = c("dplyr", "GECal", "CVXR", "nleqslv")) %dopar% {

  set.seed(iter)
  samps <- gen_twophase(pop_df, n1_obs, n2_obs)
  p1_df <- samps[[1]]
  p2_df <- samps[[2]]

  ptemp <- pt(-pop_df$X3 - 2, 3)
  pop_pi1 <- ifelse(ptemp > 0.7, 0.7, ptemp)

  pistar <- pi_star(p1_df, p2_df, nrow(pop_df), pop_df = pop_df)
  tpreg <- tp_reg(p1_df, p2_df, nrow(pop_df))
  dcpop <- 
    dc_poptots(
      p1_df,
      p2_df,
      nrow(pop_df),
      pop_tot = c(nrow(pop_df), sum(pop_df$X1), sum(pop_df$X2), sum(-pop_pi1))
    )
  dcest <-
    dc_esttots(
      p1_df,
      p2_df,
      nrow(pop_df),
      pop_gdi = sum(-pop_pi1)
    )

  return(
    tibble(Est = c("pistar", "tpreg", "dcpop", "dcest"),
           Theta = c(pistar[[1]], tpreg[[1]], dcpop[[1]], dcest[[1]]),
           Var = c(pistar[[2]], tpreg[[2]], dcpop[[2]], dcest[[2]]),
           Iter = iter)
  )

} %>% bind_rows()

stopCluster(clust)

```


```{r}
#| label: Analysis

# Find any failed estimates
which(is.na(mc_res$Theta))
which(is.na(mc_res$Var))
mc_res %>%
  mutate(iter = rep(1:B_sims, each = 4)) %>%
  filter(is.na(Theta))

# Analyze Mean
mc_res %>%
  mutate(err = Theta - true_theta) %>%
  mutate(CI = abs(err) < qnorm(0.975) * sqrt(Var)) %>%
  group_by(Est) %>%
  summarize(Bias = mean(err, na.rm = TRUE),
            RMSE = sqrt(mean(err^2, na.rm = TRUE)),
            EmpCI = mean(CI, na.rm = TRUE),
            sdest = sd(Theta, na.rm = TRUE)) %>%
  ungroup() %>%
  mutate(Ttest = abs(Bias) / sqrt(sdest^2 / B_sims)) %>%
  select(-sdest) %>%
  mutate(Ind = case_when(
    Est == "dcest" ~ 4,
    Est == "dcpop" ~ 3,
    Est == "tpreg" ~ 2,
    Est == "pistar" ~ 1)
  ) %>%
  mutate(Est = case_when(
    Est == "dcest" ~ "DC-Est",
    Est == "dcpop" ~ "DC-Pop",
    Est == "tpreg" ~ "TP-Reg",
    Est == "pistar" ~ "$\\pi^*$")
  ) %>%
  arrange(Ind) %>%
  select(Est, Bias, RMSE, EmpCI, Ttest) 

%>%
  knitr::kable("latex", booktabs = TRUE, escape = FALSE, digits = 3) %>%
  cat(file = "tables/tpdcsim_mean.tex")

# Analyze Variance
mc_res %>%
  group_by(Est) %>%
  summarize(mcvar = var(Theta, na.rm = TRUE),
            estvar = mean(Var, na.rm = TRUE),
            varvar = var(Var, na.rm = TRUE)) %>%
  ungroup() %>%
  mutate(Ttest = abs(mcvar - estvar) / sqrt(varvar / B_sims))

mc_res %>%
  filter(Est == "dcpop") %>%
  arrange(desc(Var))

mc_res %>%
  filter(Est == "dcpop") %>%
  arrange(desc(Theta))

```
