---
title: "Multi-Source Debiased Calibration Simulation 2: Multiple $A_m$"
author: "Caleb Leedy"
from: markdown+emoji
format: 
  html:
    embed-resources: true
    code-fold: true
    grid:
      margin-width: 450px
bibliography: references.bib
reference-location: margin
comments:
  hypothesis: true
---

# Summary

This report simulates multi-source sampling with the debiased
calibration of @kwon2024debiased. We check for the following:

1. Bias of $\hat Y$ and,
2. Bias of $\hat V(\hat Y)$.

For the estimator $\hat Y$ we construct 

1. Two individual HT-estimators,
2. A weighted HT-estimator,
3. The debiased calibration estimator (with known finite population total), and
4. The debiased calibration estimator with estimated population totals from the
   Phase 1 sample.

# Simulation Setup

```{r}
#| label: setup

B_sims <- 1000

N_obs <- 10000
B1_obs <- 2000
A2_obs <- 200

library(dplyr)
library(nleqslv)
library(doParallel)
library(doRNG)

```

We have the following superpopulation model with $N=$`{r} N_obs` elements:

$$
\begin{aligned}
X_{1i} &\stackrel{ind}{\sim} N(2, 1) \\
X_{2i} &\stackrel{ind}{\sim} Unif(0, 4) \\
X_{3i} &\stackrel{ind}{\sim} N(5, 1) \\
\varepsilon_i &\stackrel{ind}{\sim} N(0, 1) \\
Y_{i} &= 3 X_{1i} + 2 X_{2i} + \varepsilon_i \\
\pi_{A1i} &= \min(\max(\Phi(-x_{1i}), 0.02), 0.9)\\
\pi_{A2i} &= \min(\max(\Phi(x_{3i} - 6), 0.02), 0.95) \\
\pi_{B1i} &= n_1 / N\\
\pi_{B2i} &= \Phi(x_{2i} - 2) \\
\end{aligned}
$$

We observe the following columns in each sample

| Sample | $X_1$ | $X_2$ | $X_3$ |  $Y$ |
|:-------|------:|------:|------:|-----:|
| $A_1$  | ✓     | ✓     | ✓     |  ✓   |  
| $A_2$  | ✓     |       | ✓     |  ✓   |  
| $B_1$  | ✓     |       | ✓     |      |  
| $B_2$  | ✓     | ✓     |       |      |  

For the sampling mechanism $A_1$, $A_2$ and $B_2$ are selected using a Poisson
sample with response probabilities $\pi_{A1i}$, $\pi_{A2i}$ and $\pi_{B1i}$
respectively. The $B_1$ sample is a simple random sample (SRS).


```{r}
#| label: generate population and samples

gen_pop <- function(N_obs, B1_obs) {

  x1 <- rnorm(N_obs, 2, 1)
  x2 <- runif(N_obs, 0, 4)
  x3 <- rnorm(N_obs, 5, 1)
  z <- rnorm(N_obs, 0, 1)

  eps <- rnorm(N_obs)

  y <- 3 * x1 + 2 * x2 + eps

  piA1 <- pmin(pmax(pnorm(-x1), 0.02), 0.9)
  # piA2 <- A2_obs / N_obs
  piA2 <- pmin(pmax(pnorm(x3 - 6), 0.02), 0.95)
  piB1 <- B1_obs / N_obs
  piB2 <- pnorm(x2 - 2)

  return(tibble(X1 = x1, X2 = x2, X3 = x3, Y = y,
                piA1 = piA1, piA2 = piA2, piB1 = piB1, piB2 = piB2))
}

#' This function generates Phase 1 and Phase 2 samples from an updated
#' population with selection probabilites.
gen_samps <- function(pop_df, A1_type, A2_type, B1_type, B2_type) {

  if (A1_type == "poisson") {
    delA1 <- rbinom(nrow(pop_df), 1, pop_df$piA1)
  } else if (A1_type == "srs") {
    ind <- sample(1:nrow(pop_df), size = pop_df$piA1[1] * nrow(pop_df))
    delA1 <- as.numeric(1:nrow(pop_df) %in% ind)
  } else {
    stop("We have only implemented poisson and srs for Sample A1.")
  }

  A1_df <- mutate(pop_df, delA1 = delA1) %>% filter(delA1 == 1)

  if (A2_type == "poisson") {
    delA2 <- rbinom(nrow(pop_df), 1, pop_df$piA2)
  } else if (A2_type == "srs") {
    ind <- sample(1:nrow(pop_df), size = pop_df$piA2[1] * nrow(pop_df))
    delA2 <- as.numeric(1:nrow(pop_df) %in% ind)
  } else {
    stop("We have only implemented poisson and srs for Sample A2.")
  }

  A2_df <- mutate(pop_df, delA2 = delA2) %>% filter(delA2 == 1)

  if (B1_type == "poisson") {
    delB1 <- rbinom(nrow(pop_df), 1, pop_df$piB1)
  } else if (B1_type == "srs") {
    ind <- sample(1:nrow(pop_df), size = pop_df$piB1[1] * nrow(pop_df))
    delB1 <- as.numeric(1:nrow(pop_df) %in% ind)
  } else {
    stop("We have only implemented poisson and srs for Sample B1.")
  }

  B1_df <- mutate(pop_df, delB1 = delB1) %>% filter(delB1 == 1)

  if (B2_type == "poisson") {
    delB2 <- rbinom(nrow(pop_df), 1, pop_df$piB2)
  } else if (B2_type == "srs") {
    ind <- sample(1:nrow(pop_df), size = round(pop_df$piB2[1] * nrow(pop_df)))
    delB2 <- as.numeric(1:nrow(pop_df) %in% ind)
  } else {
    stop("We have only implemented poisson and srs for Sample B2.")
  }

  B2_df <- mutate(pop_df, delB2 = delB2) %>% filter(delB2 == 1)

  return(list(A1_df, A2_df, B1_df, B2_df))
}

```

```{r}
#| label: estimators

ht_est <- function(p_df, piAn, N_obs, type) {

  theta <- sum(p_df$Y / p_df[[piAn]]) / N_obs

  if (type == "poisson") {

    v_hat <- sum((1 - p_df[[piAn]]) / p_df[[piAn]]^2 * p_df$Y^2) / N_obs^2

  } else if (type == "srs") {

    v_hat <- (1 / nrow(p_df) - 1 / N_obs) * var(p_df$Y)

  } else {

    v_hat <- NA

  }

  return(list(theta = theta, v_hat = v_hat))
}

wht_est <- function(A1_df, A2_df, N_obs) {
  # Inverse-variance weighted average
  theta1 <- sum(A1_df$Y / A1_df$piA1) / N_obs
  theta2 <- sum(A2_df$Y / A2_df$piA2) / N_obs
  vhat1 <- sum((1 - A1_df$piA1) / A1_df$piA1^2 * A1_df$Y^2) / N_obs^2
  vhat2 <- sum((1 - A2_df$piA2) / A2_df$piA2^2 * A2_df$Y^2) / N_obs^2
  # vhat2 <- (1 / nrow(A2_df) - 1 / N_obs) * var(A2_df$Y)

  theta <- (theta1 / vhat1 + theta2 / vhat2) / (1 / vhat1 + 1 / vhat2)
  v_hat <- 1 / (1 / vhat1 + 1 / vhat2)

  return(list(theta = theta, v_hat = v_hat))
}

#' This  function does the debiased calibration
#'
#' @param zmat - A n x p matrix
#' @param w1i - A vector of length n
#' @param d2i - A vector of length n
#' @param T1 - A vector of length p
#' @param qi - A scaler or a vector of length n
#' @param entropy - One of "EL", "ET"
solveGE <- function(zmat, w1i, d2i, T1, qi, entropy) {

  f <- function(lam, zmat, w1i, d2i, T1, qi, entropy, returnw = FALSE) {

    if (entropy == "EL") {
      w <- -d2i / drop(zmat %*% lam)
    } else if (entropy == "ET") {
      w <- d2i * exp(drop(zmat %*% lam))
    } else {
      stop("We only accept entropy of EL or ET.")
    }

    if (returnw) {
      return(w)
    } else {
      return(drop((w * w1i * qi) %*% zmat) - T1)
    }
  }

  j <- function(lam, zmat, w1i, d2i, T1, qi, entropy) {
    if (entropy == "EL") {
      res <- t(zmat) %*% diag((w1i * qi * d2i) / drop(zmat %*% lam)^2) %*% zmat
    } else if (entropy == "ET") {
      res <- t(zmat) %*% diag((w1i * qi * d2i) * exp(drop(zmat %*% lam))) %*% zmat
    }

    return(res)
  }

  init <- c(rep(0, ncol(zmat) - 1), 1)
  res <- 
  nleqslv(init, f, jac = j, zmat = zmat, w1i = w1i, d2i = d2i,
          T1 = T1, qi = qi, entropy = entropy,
          method = "Newton", control = list(maxit = 1e5, allowSingular = TRUE))

  resw <- f(res$x, zmat, w1i, d2i, T1, qi, entropy, returnw = TRUE)

  if (!(res$termcd %in% c(1))) {
    return(NA)
  }

  return(resw)

}

dc_ms_ybar <- 
  function(A1_df, A2_df, B1_df, B2_df, pop_df, estT1, qi = 1, entropy = "EL", reg = FALSE) {

  dA1_vec <- 1 / (A1_df$piA1)
  dA2_vec <- 1 / (A2_df$piA2)
  if (entropy == "EL") {
    gdA1 <- -1 / dA1_vec
    gdA1p <- -1 / (1 / pop_df$piA1)
    gA1inv <- dA1_vec^2
    gdA2 <- -1 / dA2_vec
    gdA2p <- -1 / (1 / pop_df$piA2)
    gA2inv <- dA2_vec^2
  } else if (entropy == "ET") {
    gdA1 <- log(dA1_vec)
    gdA1p <- log(1 / pop_df$piA1)
    gA1inv <- dA1_vec
    gdA2 <- log(dA2_vec)
    gdA2p <- log(1 / pop_df$piA2)
    gA2inv <- dA2_vec
  } else {
    stop("This type of entropy has not yet been implemented.")
  }

  sampA1 <- cbind(rep(1, nrow(A1_df)), as.matrix(select(A1_df, X1, X2, X3)))
  sampA2 <- cbind(rep(1, nrow(A2_df)), as.matrix(select(A2_df, X1, X3)))
  zmatA1 <- cbind(sampA1, gdA1)
  zmatA2 <- cbind(sampA2, gdA2)
  w1i <- 1
  dA1i <- 1 / A1_df$piA1
  dA2i <- 1 / A2_df$piA2

  if (estT1) {
    x1_A1 <- sum(A1_df$X1 / A1_df$piA1) / N_obs
    x2_A1 <- sum(A1_df$X2 / A1_df$piA1) / N_obs
    x3_A1 <- sum(A1_df$X3 / A1_df$piA1) / N_obs

    x1_A2 <- sum(A2_df$X1 / A2_df$piA2) / N_obs
    x3_A2 <- sum(A2_df$X3 / A2_df$piA2) / N_obs

    x1_B1 <- sum(B1_df$X1 / B1_df$piB1) / N_obs
    x3_B1 <- sum(B1_df$X3 / B1_df$piB1) / N_obs

    x1_B2 <- sum(B2_df$X1 / B2_df$piB2) / N_obs
    x2_B2 <- sum(B2_df$X2 / B2_df$piB2) / N_obs

    xhat <- c(x1_A1, x2_A1, x3_A1, x1_A2, x3_A2, x1_B1, x3_B1, x1_B2, x2_B2)
    x_mat <- 
    matrix(c(1, 0, 0,
             0, 1, 0,
             0, 0, 1,
             1, 0, 0,
             0, 0, 1,
             1, 0, 0,
             0, 0, 1,
             1, 0, 0,
             0, 1, 0), ncol = 3, byrow = TRUE)
    vmat <- matrix(0, nrow = 9, ncol = 9)
    vmat[1, 1] <- sum((1 / A1_df$piA1^2 - 1 / A1_df$piA1) * A1_df$X1^2) / nrow(pop_df)^2
    vmat[1, 2] <- 
      sum((1 / A1_df$piA1^2 - 1 / A1_df$piA1) * A1_df$X1 * A1_df$X2) / nrow(pop_df)^2
    vmat[1, 3] <-
      sum((1 / A1_df$piA1^2 - 1 / A1_df$piA1) * A1_df$X1 * A1_df$X3) / nrow(pop_df)^2
    vmat[2, 1] <- vmat[1, 2]
    vmat[3, 1] <- vmat[1, 3]
    vmat[2, 2] <- sum((1 / A1_df$piA1^2 - 1 / A1_df$piA1) * A1_df$X2^2) / nrow(pop_df)^2
    vmat[2, 3] <-
      sum((1 / A1_df$piA1^2 - 1 / A1_df$piA1) * A1_df$X2 * A1_df$X3) / nrow(pop_df)^2
    vmat[3, 2] <- vmat[2, 3]
    vmat[3, 3] <- sum((1 / A1_df$piA1^2 - 1 / A1_df$piA1) * A1_df$X3^2) / nrow(pop_df)^2

    vmat[4, 4] <- sum((1 / A2_df$piA2^2 - 1 / A2_df$piA2) * A2_df$X1^2) / nrow(pop_df)^2
    vmat[5, 5] <- sum((1 / A2_df$piA2^2 - 1 / A2_df$piA2) * A2_df$X3^2) / nrow(pop_df)^2
    vmat[4, 5] <- sum((1 / A2_df$piA2^2 - 1 / A2_df$piA2) * 
      A2_df$X1 * A2_df$X3) / nrow(pop_df)^2
    vmat[5, 4] <- vmat[4, 5]

    vmat[6, 6] <- (1 / nrow(B1_df) - 1 / nrow(pop_df)) * var(B1_df$X1)
    vmat[7, 7] <- (1 / nrow(B1_df) - 1 / nrow(pop_df)) * var(B1_df$X3)
    vmat[6, 7] <- (1 / nrow(B1_df) - 1 / nrow(pop_df)) * cov(B1_df$X1, B1_df$X3)
    vmat[7, 6] <- vmat[6, 7]

    vmat[8, 8] <- sum((1 / B2_df$piB2^2 - 1 / B2_df$piB2) * B2_df$X1^2) / nrow(pop_df)^2
    vmat[9, 9] <- sum((1 / B2_df$piB2^2 - 1 / B2_df$piB2) * B2_df$X2^2) / nrow(pop_df)^2
    vmat[8, 9] <- 
      sum((1 / B2_df$piB2^2 - 1 / B2_df$piB2) * B2_df$X1 * B2_df$X2) / nrow(pop_df)^2
    vmat[9, 8] <- vmat[8, 9]

    xgls <- drop(MASS::ginv(t(x_mat) %*% solve(vmat) %*% x_mat) %*% 
                (t(x_mat) %*% solve(vmat) %*% xhat))

    TA1 <- c(nrow(pop_df),
            xgls[1] * nrow(pop_df),
            xgls[2] * nrow(pop_df),
            xgls[3] * nrow(pop_df),
            sum(gdA1p * qi))
    TA2 <- c(nrow(pop_df),
            xgls[1] * nrow(pop_df),
            xgls[3] * nrow(pop_df),
            sum(gdA2p * qi))
  } else {
    TA1 <- c(nrow(pop_df),
            sum(pop_df$X1),
            sum(pop_df$X2),
            sum(pop_df$X3),
            sum(gdA1p * qi))
    # We have some misspecification in A2
    TA2 <- c(nrow(pop_df),
            sum(pop_df$X1),
            sum(pop_df$X3),
            sum(gdA2p * qi))
  }

  dc_wA1 <- solveGE(zmatA1, w1i, dA1i, TA1, qi, entropy)
  dc_wA2 <- solveGE(zmatA2, w1i, dA2i, TA2, qi, entropy)

  # Mean Estimation
  thetaA1 <- sum(A1_df$Y * dc_wA1 * w1i) / nrow(pop_df)
  thetaA2 <- sum(A2_df$Y * dc_wA2 * w1i) / nrow(pop_df)
  theta <- (thetaA1 + thetaA2) / 2

  zA1_dc <- model.matrix(~1 + A1_df$X1 + A1_df$X2 + A1_df$X3 + gdA1)
  zA2_dc <- model.matrix(~1 + A2_df$X1 + A2_df$X3 + gdA2)

  gamA1_dc <- 
    solve(t(zA1_dc) %*% diag(dA1i * gA1inv * qi) %*% zA1_dc,
          t(zA1_dc) %*% diag(dA1i * gA1inv) %*% A1_df$Y)
  gamA2_dc <- 
    solve(t(zA2_dc) %*% diag(dA2i * gA2inv * qi) %*% zA2_dc,
          t(zA2_dc) %*% diag(dA2i * gA2inv) %*% A2_df$Y)

  coefsA1 <- as.numeric(gamA1_dc)
  coefsA2 <- as.numeric(gamA2_dc)
  uA1_mat <- 
  matrix(c(rep(1, nrow(A1_df)), A1_df$X1, A1_df$X2, A1_df$X3, gdA1 * qi), ncol = 5)
  uA2_mat <- 
  matrix(c(rep(1, nrow(A2_df)), A2_df$X1, A2_df$X3, gdA2 * qi), ncol = 4)
  epsA1 <- (A1_df$Y - drop(uA1_mat %*% coefsA1))
  epsA2 <- (A2_df$Y - drop(uA2_mat %*% coefsA2))

  if (estT1) {
    # Variance Estimation
    # This is the variance of bar x gls not x gls total.
    var_x <- MASS::ginv(t(x_mat) %*% MASS::ginv(vmat) %*% x_mat)
    coefs <- c(coefsA1[2] + coefsA2[2], coefsA1[3], coefsA1[4] + coefsA2[3])

    v1 <- matrix(coefs, nrow = 1) %*% var_x %*% matrix(coefs, ncol = 1)
    v2A1 <- sum((1 - A1_df$piA1) / A1_df$piA1^2 * epsA1^2) / nrow(pop_df)^2
    v2A2 <- sum((1 - A2_df$piA2) / A2_df$piA2^2 * epsA2^2) / nrow(pop_df)^2
    # v2A2 <- (1 / nrow(A2_df) - 1 / nrow(pop_df)) * var(epsA2)
    v_hat <- (v1 + v2A1 + v2A2) / 4
  } else {
    v2A1 <- sum((1 - A1_df$piA1) / A1_df$piA1^2 * epsA1^2) / nrow(pop_df)^2
    v2A2 <- sum((1 - A2_df$piA2) / A2_df$piA2^2 * epsA2^2) / nrow(pop_df)^2
    # v2A2 <- (1 / nrow(A2_df) - 1 / nrow(pop_df)) * var(epsA2)
    v_hat <- (v2A1 + v2A2) / 4
  }
  if (reg) {
    thetaA1 <- 
    (drop(TA1 %*% gamA1_dc) + 
      sum(1 / A1_df$piA1 * (A1_df$Y - drop(zA1_dc %*% gamA1_dc)))) / nrow(pop_df) 
    thetaA2 <- 
    (drop(TA2 %*% gamA2_dc) + 
      sum(1 / A2_df$piA2 * (A2_df$Y - drop(zA2_dc %*% gamA2_dc)))) / nrow(pop_df) 
    theta <- (thetaA1 + thetaA2) / 2
  }

  return(list(theta = theta, v_hat = as.numeric(v_hat)))
}

```


```{r}
#| label: run MCMC

set.seed(1)
pop_df <- gen_pop(N_obs, B1_obs)
true_theta <- mean(pop_df$Y)

clust <- makeCluster(min(detectCores() - 2, 100), outfile = "")
registerDoParallel(clust)

mc_res <- 
  foreach(iter=1:B_sims,
          .packages = c("dplyr", "nleqslv"),
          .options.RNG = 1) %dorng% {

    if (iter %% 100 == 0) {
      print(paste0("Iter: ", iter))
    }

    samps <- gen_samps(pop_df, "poisson", "poisson", "srs", "poisson")
    A1_df <- samps[[1]]
    A2_df <- samps[[2]]
    B1_df <- samps[[3]]
    B2_df <- samps[[4]]

    htA1 <- ht_est(A1_df, "piA1", N_obs, "poisson")
    htA2 <- ht_est(A2_df, "piA2", N_obs, "poisson")
    wht <- wht_est(A1_df, A2_df, N_obs)
    ms_pop <- dc_ms_ybar(A1_df, A2_df, B1_df, B2_df, pop_df, estT1 = FALSE)
    ms_est <- dc_ms_ybar(A1_df, A2_df, B1_df, B2_df, pop_df, estT1 = TRUE)
    ms_reg <- dc_ms_ybar(A1_df, A2_df, B1_df, B2_df, pop_df, estT1 = TRUE, reg = TRUE)

    return(
    tibble(
      Est = c("HTA1", "HTA2", "WHT", "MSPop", "MSEst", "MSReg"),
      Theta = c(htA1[[1]], htA2[[1]], wht[[1]], ms_pop[[1]], ms_est[[1]], ms_reg[[1]]),
      Var = c(htA1[[2]], htA2[[2]], wht[[2]], ms_pop[[2]], ms_est[[2]], ms_reg[[2]]),
      Iter = iter)
    )

  } %>% bind_rows()

stopCluster(clust)

```

```{r}
#| label: analyze results

# Check for failures
filter(mc_res, is.na(Theta))

# Analyze Mean
mc_res %>%
  mutate(err = Theta - true_theta) %>%
  mutate(CI = abs(err) < qnorm(0.975) * sqrt(Var)) %>%
  group_by(Est) %>%
  summarize(Bias = mean(err, na.rm = TRUE),
            RMSE = sqrt(mean(err^2, na.rm = TRUE)),
            EmpCI = mean(CI, na.rm = TRUE),
            sdest = sd(Theta, na.rm = TRUE)) %>%
  ungroup() %>%
  mutate(Ttest = abs(Bias) / sqrt(sdest^2 / B_sims)) %>%
  select(-sdest) %>%
  mutate(Ind = case_when(
    Est == "MSReg" ~ 6,
    Est == "MSEst" ~ 5,
    Est == "MSPop" ~ 4,
    Est == "WHT" ~ 3,
    Est == "HTA2" ~ 2,
    Est == "HTA1" ~ 1)
  ) %>%
  arrange(Ind) %>%
  select(Est, Bias, RMSE, EmpCI, Ttest) 

%>%
  knitr::kable("latex", booktabs = TRUE, digits = 4) %>%
  cat(file = "tables/msdcsim2.tex")

# Analyze Variance
mc_res %>%
  group_by(Est) %>%
  summarize(MCVar = var(Theta, na.rm = TRUE),
            EstVar = mean(Var, na.rm = TRUE),
            VarVar = var(Var, na.rm = TRUE)) %>%
  ungroup() %>%
  mutate(Ttest = abs(MCVar - EstVar) / sqrt(VarVar / B_sims)) 


%>%
  knitr::kable("latex", booktabs = TRUE, escape = FALSE, digits = 4) %>%
  cat(file = "tables/msdcsim2_var.tex")

```
