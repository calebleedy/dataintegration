\documentclass[12pt]{article}

\usepackage{amsmath, amssymb, mathrsfs, fancyhdr}
\usepackage{syntonly, lastpage, hyperref, enumitem, graphicx}
\usepackage{biblatex}
\usepackage{booktabs}
\usepackage{float}

\addbibresource{references.bib}

\hypersetup{colorlinks = true, urlcolor = black}

\headheight     15pt
\topmargin      -1.5cm   % read Lamport p.163
\oddsidemargin  -0.04cm  % read Lamport p.163
\evensidemargin -0.04cm  % same as oddsidemargin but for left-hand pages
\textwidth      16.59cm
\textheight     23.94cm
\parskip         7.2pt   % sets spacing between paragraphs
\parindent         0pt   % sets leading space for paragraphs
\pagestyle{empty}        % Uncomment if don't want page numbers
\pagestyle{fancyplain}

\newcommand{\MAP}{{\text{MAP}}}
\newcommand{\argmax}{{\text{argmax}}}
\newcommand{\argmin}{{\text{argmin}}}
\newcommand{\Cov}{{\text{Cov}}}
\newcommand{\Var}{{\text{Var}}}
\newcommand{\logistic}{{\text{logistic}}}

\begin{document}

%\lhead{Caleb Leedy}
\chead{Nonmonotone Missingness}
%\chead{STAT 615 - Advanced Bayesian Methods}
%\rhead{Page \thepage\ of \pageref{LastPage}}
\rhead{January 25, 2024}

\section*{Simulation Study Setup}

We use the following simulation setup

\begin{align*}
  \begin{bmatrix} x \\ e_1 \\ e_2 \end{bmatrix} 
  &\stackrel{ind}{\sim} N\left(\begin{bmatrix} 0 \\ 0 \\ 0 \end{bmatrix}, 
  \begin{bmatrix} 1 & 0 & 0 \\ 0 & 1 & \rho \\ 0 & \rho & 1 \end{bmatrix}\right) \\
  y_1 &= x + e_1 \\
  y_2 &= \mu + x + e_2 \\
\end{align*}

This yields outcome variables $Y_1$ and $Y_2$ that are correlated both with $X$
and additionally with each other. To generate the missingness pattern, we draw 
from a categorical distribution with selection probabilities $(\pi_{00}, \pi_{10},
\pi_{01}, \pi_{11})$. Each selection probability, $\pi_{j_1, j_2}$ indicates 
the probability that an observation is selected into a segment $A_{j_1, j_2}$ 
where $A_{00}$ indicates that only $X$ is observed, $A_{10}$ means that $X$ and
$Y_1$ are observed, $A_{01}$ has only $X$ and $Y_2$ observed, and $A_{11}$
observes $X$, $Y_1$, and $Y_2$.

% I change theta to mu.
In addition to varying the values of the parameters $\mu$ and $\rho$, there
are two main factors of the simulation that change: the distribution of the
categories and the parameter of interest, $\theta$. In a ``balanced''
distribution, we have the following selection probabilities: $\pi_{00} = 0.2$,
$\pi_{10} = 0.2$, $\pi_{01} = 0.2$, and $\pi_{11} = 0.4$. In the ``unbalanced''
distribution we have $\pi_{00} = 0.3$, $\pi_{10} = 0.4$, $\pi_{01} = 0.1$, and
$\pi_{11} = 0.2$. The two types of $\theta$ values that we consider are a
linear estimate, $\theta = E[g(Z)] = E[Y_2]$ and a non-linear estimate, 
$\theta = E[g(Z)] = E[Y_1^2 Y_2]$. For notational purposes, we define $Z = (X,
Y, Z)$ and occasionally we will use the notation $G_r(Z)$ to indicate the
general form of the observed data in rth segment. We also use $n$ to denote to
total number of observations in the sample. While $n$ is known, due to our
setup, the number of elements in each segment $A_{j_1, j_2}$ is random.

There are several algorithms for comparison which are defined as the following:

\begin{align*}
  Oracle &= n^{-1} \sum_{i = 1}^n g(Z_i)\\
  CC &= \frac{\sum_{i = 1}^n \delta_{11} g(Z_i)}{\sum_{i = 1}^n \delta_{11}} \\
  IPW &= \sum_{i = 1}^n \frac{\delta_{11}}{\pi_{11}} g(Z_i)\\
\end{align*}



\end{document}
