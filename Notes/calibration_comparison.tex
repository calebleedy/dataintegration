
\documentclass[12pt]{article}

\usepackage{amsmath, amssymb, mathrsfs, fancyhdr}
\usepackage{syntonly, lastpage, hyperref, enumitem, graphicx}
\usepackage{biblatex}
\usepackage{booktabs}
\usepackage{float}

\addbibresource{references.bib}

\hypersetup{colorlinks = true, urlcolor = black}

\headheight     15pt
\topmargin      -1.5cm   % read Lamport p.163
\oddsidemargin  -0.04cm  % read Lamport p.163
\evensidemargin -0.04cm  % same as oddsidemargin but for left-hand pages
\textwidth      16.59cm
\textheight     23.94cm
\parskip         7.2pt   % sets spacing between paragraphs
\parindent         0pt   % sets leading space for paragraphs
\pagestyle{empty}        % Uncomment if don't want page numbers
\pagestyle{fancyplain}

\newcommand{\MAP}{{\text{MAP}}}
\newcommand{\argmax}{{\text{argmax}}}
\newcommand{\argmin}{{\text{argmin}}}
\newcommand{\Cov}{{\text{Cov}}}
\newcommand{\Var}{{\text{Var}}}
\newcommand{\logistic}{{\text{logistic}}}

\begin{document}

%\lhead{Caleb Leedy}
\chead{Nonmonotone Missingness}
%\chead{STAT 615 - Advanced Bayesian Methods}
%\rhead{Page \thepage\ of \pageref{LastPage}}
\rhead{April 4, 2023}

\section*{Comparison with Calibration Estimator}

% Outline
% * [ ] Regression estimator comparison with calibration in monotone case
% * [ ] Equivalent calibration in nonmonotone case

\subsection*{Monotone Case}

\begin{itemize}
  \item In the monotone case the efficient estimator is 

    \begin{align*}
      \hat \theta_{eff} &= n^{-1} \sum_{i = 1}^n E[g_i \mid X_i] \\
      &+ n^{-1} \sum_{i = 1}^n \frac{R_{1i}}{\pi_{1+}(X_i)}(
        E[g_i \mid X_i, Y_{1i}] - E[g_i \mid X_i]) \\
      &+ n^{-1} \sum_{i = 1}^n \frac{R_{1i} R_{2i}}{\pi_{11}(X_i)} (
      E[g_i \mid X_i, Y_{1i}, Y_{2i}] - E[g_i \mid X_i, Y_{1i}]). 
    \end{align*}

  \item This should be very similar to the following calibration estimator, for
    $\sum_{i = 1}^n w_i y_{2i}$

    \begin{align*}
      \argmin_w \sum_{i = 1}^n w_i^2& \text{ such that }\\
      \sum_{i = 1}^n x_i &= \sum_{i = 1}^n R_{1i} w_{1i} x_i \\
      \sum_{i = 1}^n w_{1i} (x_i, y_{1i}) &= \sum_{i = 1}^n R_{1i} R_{2i} w_{2i}
      (x_i, y_{1i}) \\
    \end{align*}
  
  \item The reason that these should be the same is because they are similar in
    relationship to a calibration and regression estimator which are exactly the
    same.
    
  \item % TODO: Add simulation study results
\end{itemize}

\subsection*{Nonmonotone Case}

\begin{itemize}
  \item Similar to the monotone case, we have an idea of the efficient
    estimator. Now we want to show that it is similar to a calibration equation.
    Unlike the monotone case where $R_{1i} = 0$ implies $R_{2i} = 0$, the
    nonmonotone case does not have this relationship. Instead we believe that we
    have the following calibration equations:

    \begin{align*}
      \sum_{i = 1}^n E[g_i \mid X_i] &= \sum_{i = 1}^n R_{1i} w_{1i} E[g_i \mid
      X_i]\\
      \sum_{i = 1}^n E[g_i \mid X_i] &= \sum_{i = 1}^n R_{2i} w_{2i} E[g_i \mid
      X_i]\\
      \sum_{i = 1}^n R_{1i} w_{1i} E[g_i \mid X_i, Y_{1i}] &= \sum_{i = 1}^n
      R_{1i} R_{2i} w_{ci} E[g_i \mid X_i, Y_{1i}]\\
      \sum_{i = 1}^n R_{2i} w_{2i} E[g_i \mid X_i, Y_{1i}] &= \sum_{i = 1}^n
      R_{1i} R_{2i} w_{ci} E[g_i \mid X_i, Y_{2i}]\\
      \sum_{i = 1}^n E[g_i \mid X_i] &= \sum_{i = 1}^n R_{1i} R_{2i} w_{ci}
      E[g_i \mid X_i].
    \end{align*}
  
  \item % TODO: Add simulation results
\end{itemize}












\newpage
\end{document}
