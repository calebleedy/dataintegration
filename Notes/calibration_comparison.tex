
\section*{Comparison with Calibration Estimator}

% Outline
% * [X] Regression estimator comparison with calibration in monotone case
% * [X] Equivalent calibration in nonmonotone case

\subsection*{Monotone Case}

\begin{itemize}
  \item In the monotone case the efficient estimator is 

    \begin{align*}
      \hat \theta_{eff} &= n^{-1} \sum_{i = 1}^n E[g_i \mid X_i] \\
      &+ n^{-1} \sum_{i = 1}^n \frac{R_{1i}}{\pi_{1+}(X_i)}(
        E[g_i \mid X_i, Y_{1i}] - E[g_i \mid X_i]) \\
      &+ n^{-1} \sum_{i = 1}^n \frac{R_{1i} R_{2i}}{\pi_{11}(X_i)} (
      E[g_i \mid X_i, Y_{1i}, Y_{2i}] - E[g_i \mid X_i, Y_{1i}]). 
    \end{align*}

  \item This should be very similar to the following calibration estimator, for
    $\sum_{i = 1}^n w_i y_{2i}$

    \begin{align*}
      \argmin_w \sum_{i = 1}^n w_i^2& \text{ such that }\\
      \sum_{i = 1}^n x_i &= \sum_{i = 1}^n R_{1i} w_{1i} x_i \\
      \sum_{i = 1}^n w_{1i} (x_i, y_{1i}) &= \sum_{i = 1}^n R_{1i} R_{2i} w_{2i}
      (x_i, y_{1i}) \\
    \end{align*}
  
  \item The reason that these should be the same is because they are similar in
    relationship to a calibration and regression estimator which are exactly the
    same.
    
  \item To test the idea that the monotone regression estimator is similar to
    the calibration estimator we run several simulation studies. In the monotone
    case data is generating in the following steps:

    \begin{enumerate}
      \item The variables $X$, $Y_1$, and $Y_2$ are simulated from the following
        distributions:
        \begin{align*}
          X_i &\stackrel{iid}{\sim} N(0, 1) \\
          Y_{1i} &\stackrel{iid}{\sim} N(0, 1) \\
          Y_{2i} &\stackrel{iid}{\sim} N(\theta, 1).
        \end{align*}

      \item After the variables have been simulated, we see which variables are
        observed. We always observe $X_i$. We observed $Y_1$ with
        probability $p_{1i} \propto \logistic(x_i)$. If $Y_{1i}$ is observed,
        then we observe $Y_{2i}$ with probability $p_{2i} \propto
        \logistic(y_{1i})$. If $Y_{1i}$ is not observed, we do not observe
        $Y_{2i}$.
    \end{enumerate}

  \item The goal of this simulation study is the estimate $\theta = E[Y_2]$. We
    use the previous monotone data generating process with different true values
    of $\theta$ and compute the bias, standard deviation, T-statistic and
    p-value. (The T-statistic and p-value test if the estimated value of $\hat
    \theta$ is significantly different from the true value of $\theta$.)

    \input{Tables/calimono_t-5.tex}
    \input{Tables/calimono_t0.tex}
    \input{Tables/calimono_t5.tex}

\end{itemize}

\newpage

\subsection*{Nonmonotone Case}

\begin{itemize}
  \item Similar to the monotone case, we have an idea of the efficient
    estimator. Now we want to show that it is similar to a calibration equation.
    Unlike the monotone case where $R_{1i} = 0$ implies $R_{2i} = 0$, the
    nonmonotone case does not have this relationship. Instead we believe that we
    have the following calibration equations:

    \begin{align*}
      \sum_{i = 1}^n E[g_i \mid X_i] &= \sum_{i = 1}^n R_{1i} w_{1i} E[g_i \mid
      X_i]\\
      \sum_{i = 1}^n E[g_i \mid X_i] &= \sum_{i = 1}^n R_{2i} w_{2i} E[g_i \mid
      X_i]\\
      \sum_{i = 1}^n R_{1i} w_{1i} E[g_i \mid X_i, Y_{1i}] &= \sum_{i = 1}^n
      R_{1i} R_{2i} w_{ci} E[g_i \mid X_i, Y_{1i}]\\
      \sum_{i = 1}^n R_{2i} w_{2i} E[g_i \mid X_i, Y_{1i}] &= \sum_{i = 1}^n
      R_{1i} R_{2i} w_{ci} E[g_i \mid X_i, Y_{2i}]\\
      \sum_{i = 1}^n E[g_i \mid X_i] &= \sum_{i = 1}^n R_{1i} R_{2i} w_{ci}
      E[g_i \mid X_i].
    \end{align*}
  
  \item We still have the same goal of the simulation study: estimate $\theta =
    E[Y_2]$. We use the previous nonmonotone data generating process with
    different true values of $\theta$ to estimate the bias, standard deviation,
    T-statistic, and p-value. For clarity here is a reminder of the simulation
    setup.

    \begin{enumerate}
      \item Generate $X_i$, $\varepsilon_{1i}$, and $\varepsilon_{2i}$ from the
        following distributions:

        \begin{align*}
          x_i &\stackrel{iid}{\sim} N(0, 1)\\
          \varepsilon_{1i} &\stackrel{iid}{\sim} N(0, 1)\\
          \varepsilon_{2i} &\stackrel{iid}{\sim} N(\theta, 1)\\
        \end{align*}

        Then we have
        \[y_{1i} = x_i + \varepsilon_{1i} \text{ and } y_{2i} = x_i +
        \varepsilon_{2i}.\]

      \item Then we have to select the variables to observe. We always observe
        $X_i$. Then we choose to either observe $Y_1$ with probability $0.4$,
        $Y_2$ with probability $0.4$ or neither with probability $0.2$.

      \item If neither then $R_{1i} = 0$ and $R_{2i} = 0$. If we observe $Y_1$
        then $R_1 = 1$ and if we observe $Y_2$ then $R_2 = 1$.

      \item If we observe either $Y_1$ or $Y_2$ then with probability $p \propto
        \logistic(Y_k)$ where $Y_k$ is the observed $Y$ variable we choose to
        observe the other $Y$ variable.

      \item If the other $Y$ variable is observed then the corresponding $R_k =
        1$. Otherwise, $R_k = 0$.
    \end{enumerate}

  \item For this simulation setup, we estimate $\theta = E[Y_2]$. Like the
    previous nonmonotone simulations, we compare this calibration estimator to
    the oracle estimator which uses the average value of $Y_2$ if $R_2 = 0$ or
    $R_2 = 1$, an IPW estimator with the correct weights, and the proposed
    regression estimator. These are currently run with a sample size of $n =
    1000$ with the number of Monte Carlo simulations of $B = 1000$.

    \input{Tables/calinonmono1m-5.tex}
    \input{Tables/calinonmono1m0.tex}
    \input{Tables/calinonmono1m5.tex}

\end{itemize}

\newpage
