\documentclass[12pt]{article}

\usepackage{amsmath, amssymb, mathrsfs, fancyhdr}
\usepackage{syntonly, lastpage, hyperref, enumitem, graphicx}
\usepackage{biblatex}
\usepackage{booktabs}
\usepackage{float}

\addbibresource{references.bib}

\hypersetup{colorlinks = true, urlcolor = black}

\headheight     15pt
\topmargin      -1.5cm   % read Lamport p.163
\oddsidemargin  -0.04cm  % read Lamport p.163
\evensidemargin -0.04cm  % same as oddsidemargin but for left-hand pages
\textwidth      16.59cm
\textheight     23.94cm
\parskip         7.2pt   % sets spacing between paragraphs
\parindent         0pt   % sets leading space for paragraphs
\pagestyle{empty}        % Uncomment if don't want page numbers
\pagestyle{fancyplain}

\newcommand{\MAP}{{\text{MAP}}}
\newcommand{\argmax}{{\text{argmax}}}
\newcommand{\argmin}{{\text{argmin}}}
\newcommand{\Cov}{{\text{Cov}}}
\newcommand{\logistic}{{\text{logistic}}}

\begin{document}

%\lhead{Caleb Leedy}
\chead{Nonmonotone Missingness}
%\chead{STAT 615 - Advanced Bayesian Methods}
%\rhead{Page \thepage\ of \pageref{LastPage}}
\rhead{April 4, 2023}

\section*{Overview:}

The goal of this project is to outperform existing techniques in the literature
related to nonmonotone missing data.

\section*{Initial Simulations:}
% Tables generated from Simulations/nonmonotone.R

\begin{itemize}
  \item \textbf{Implemented simulation of monotone MAR data}: This is 
  correspondingly easier
  than the subsequent nonmonotone MAR simulation. For this simulation we use the 
  following approach:
  \begin{enumerate}
      \item Generate $X$, $Y_1$, and $Y_2$ for elements $i = 1, \dots, n$.
      \item Using the covariate $X$, determine the probability $p_1$ of $Y_1$
      being observed for each element $i$.
      \item Based on $p_1$, determine if $R_1 = 1$.
      \item If $R_1 = 0$, then $R_2 = 0$. Otherwise, using variables $X$ and
        $Y_1$, determine the probability $p_{12}$.
      \item Based on $p_{12}$ determine if $R_2 = 1$.
  \end{enumerate}
  At the end of the algorithm, we have determined the values of binary variables
    $R_1$ and $R_2$ for each $i$ and if either of them are equal to 1, the
    corresponding level of $Y_{k}$. As is common in this literature, the values
    of $R_1$ and $R_2$ determine if the corresponding variable $Y_1$ or $Y_2$ is
    missing or observed with $R = 1$ indicating $Y$ being observed.
  
  \item \textbf{Implemented simulation of nonmonotone MAR data}: 
  Following the approach
    of \cite{robins1997non}, I construct a nonmonotone MAR simulation with two 
    response variables $Y_1$ and $Y_2$ and one covariate $X$. The algorithm to
    generate the data is the following:
    \begin{enumerate}
        \item Generate $X$, $Y_1$, and $Y_2$ for elements $i = 1, \dots, n$.
        \item Using the covariate $X_i$, generate probabilities for each element
          $i$ $p_0$, $p_1$, and $p_2$ such that $p_0 + p_1 + p_2 = 1$. 
        \item Select one option based on the three probabilities for each
          element $i$. If 0 is selected: $R_1 = 0$ and $R_2 = 0$. If 1 is
          selected $R_1 = 1$. If 2 is selected, $R_2 = 1$.
        \item We take the next step in multiple cases. If 0 was selected, we are
          done. If 1 was selected, we generate probabilities $p_{12}$ based on
          $X$ and $Y_1$. Then based on this probability, we determine if $R_2 =
          1$. In the same manner, if 2 was selected in the previous step, we
          generate probabilities $p_{21}$ based on $X$ and $Y_2$. Then based on
          this probability, we determine if $R_2 = 1$.
    \end{enumerate}
    Like the monotone MAR simulation this algorithm produces similar final
    results with the determination of binary variables $R_1$ and $R_2$ and
    variables $X$, $Y_1$, and $Y_2$. Unlike the monotone MAR case, the
    nonmonotone MAR includes observations with $Y_2$ observed and $Y_1$ missing.
    
  \item \textbf{Simulation 1 with Monotone MAR}:
    Following the algorithm described in the monotone MAR simulation bullet, 
    we first generate data from the following distributions:
    \begin{align*}
        X_i &\stackrel{iid}{\sim} N(0, 1) \\
        Y_{1i} &\stackrel{iid}{\sim} N(0, 1)\\
        Y_{2i} &\stackrel{iid}{\sim} N(\theta, 1)
    \end{align*}

    Then, we create the probabilities $p_1 = \logistic(x_i)$ and 
    $p_{12} = \logistic(y_{1i})$.
    Since, both $x_i$ and $y_1$ are standard normal distributions, each of these
    probabilities is approximately $0.5$ in expectation.

    The goal of this simulation is to estimate $\theta$. Alternatively, we can
    express this as solving the estimating equation:

    \[g(\theta) \equiv Y_2 - \theta = 0.\]

    We estimate $\theta$ using the following procedures:

    \begin{itemize}
        \item Oracle: This computes $\bar Y$ using \textit{both} the observed
          and missing data.
        \item IPW-Oracle: This is an IPW estimator using only the observed
          values of $Y_2$. The weights (inverse probabilities) use the actual
          probabilities.
        \item IPW-Est: This is an IPW estimator using the probabilities that
          have been estimated by a logistic model.
        \item Semi: This is the monotone semiparametric efficient estimator from
          Slide 11 (Equation 2) of Dr. Kim's Nonmonotone Missingness
          presentation.
    \end{itemize}

    We run this simulation with different values of $\theta$, sample size of
    2000, and 2000 Monte Carlo replications. Each algorithm for each replication
    generates $\hat \theta$. In the subsequent tables, we compute the bias,
    standard deviation (sd), t-statistic (where we test for a significant
    difference between the Monte Carlo mean $\hat \theta$ and the true $\theta$)
    and the p-value of the t-statistic.
    
    \newpage 

    \input{Tables/monomar_t-5.tex}
    \input{Tables/monomar_t0.tex}
    \input{Tables/monomar_t5.tex}

    Overall, these results are mostly what I would have expected. All of the
    algorithms estimate the true value of $\theta$ correctly in each case, with
    the oracle estimate having the smallest variance followed by the
    semiparametric algorithm. If there is anything surprising it is that the IPW
    estimator has better performance with the estimated weights compared to the
    true weights. However, I think that this is a known phenomenon.

    \newpage 
    
    \item \textbf{Simulation 1 with Nonmonotone MAR}:

    We generate variables $(X, Y_1, Y_2)$ using the following setup:

    \[\begin{bmatrix}
    X_i \\ \varepsilon_{1i} \\ \varepsilon_{2i}
    \end{bmatrix} \stackrel{iid}{\sim}
    N\left(
    \begin{bmatrix}
        0 \\ 0 \\ \theta
    \end{bmatrix},
    \begin{bmatrix}
        1 & 0 & 0 \\
        0 & 1 & \sigma_{yy}\\
        0 & \sigma_{yy} & 1
    \end{bmatrix}
    \right).\]

    Then, 

    \[y_{1i} = x_i + \varepsilon_{1i} \text{ and } 
    y_{2i} = x_i + \varepsilon_{2i}.\]

    Since we have nonmonotone data, our ``Stage 1'' probabilities are
    different. We compute the true Stage 1 probabilities being proportional to
    the following values:
    
    \begin{align*}
        p_0 &= 0.2 \\
        p_1 &= 0.4 \\
        p_2 &= 0.4 \\
    \end{align*}
    
   However, we keep the same structure for the Stage 2 probabilities with:
   $p_{12} = \logistic(y_1)$ and $p_{21} = \logistic(y_2)$. The goal remains to
   estimate $\theta$. We continue to use the Oracle algorithm and the IPW-Oracle
   algorithm. Since we have nonmonotone MAR data, we use the ``Proposed''
   algorithm that is described on Slide 25 (Equation 12) of Dr. Kim's
   presentation. The outcome models were estimated using
   logistic regression and OLS and correctly specified. The response model used
   the oracle estimates of the probabilities. This yields the
   following results:
   
    \input{Tables/nonmonosim1m-5.tex}
    \input{Tables/nonmonosim1m0.tex}
    \input{Tables/nonmonosim1m5.tex}

    \newpage
    
    \item \textbf{Simulation 2 with Nonmonotone MAR}:
    We also want to simulate data that is correlated. For this simulation, we
    focus on $\Cov(Y_1, Y_2)$. The data generating process now has $\sigma_{yy}
    \neq 0$. We are still interested in $\bar Y_2$ and we still run 2000
    simulation with 2000 observations. In all of the next simulations the true
    value of $\theta = 0$. The results are the following:

    \input{Tables/nonmonosim2c0.1.tex}
    \input{Tables/nonmonosim2c0.5.tex}
    \input{Tables/nonmonosim2c0.9.tex}

    \newpage

  \item \textbf{Simulation 3 with Nonmonotone MAR}:
    This simulation aims to see if the proposed algorithm is doubly robust.
    First, we check with a misspecified outcome model. In this case the data
    generating procedure is the following:

    \[\begin{bmatrix}
    X_i \\ \varepsilon_{1i} \\ \varepsilon_{2i}
    \end{bmatrix} \stackrel{iid}{\sim}
    N\left(
    \begin{bmatrix}
        0 \\ 0 \\ \theta
    \end{bmatrix},
    \begin{bmatrix}
        1 & 0 & 0 \\
        0 & 1 & \sigma_{yy}\\
        0 & \sigma_{yy} & 1
    \end{bmatrix}
    \right).\]

    Then, 

    \[y_{1i} = x_i + x_i^2 \varepsilon_{1i} \text{ and } 
    y_{2i} = -x_i + x_i^3 + \varepsilon_{2i}.\]

    This procedure causes $X$ to influence both $Y_1$ and $Y_2$ and we still
    have correlation in the error terms of $Y_1$ and $Y_2$. However, since
    neither $Y_1$ nor $Y_2$ are linear in $X$, the model will be misspecified.
    The response mechanisms are first generated MCAR with a probability of
    either $Y_1$ or $Y_2$ being the first variable observed to be $0.4$. (There
    is a $0.2$ probability neither is observed.) Then the probability of the
    other variable being observed is proportional to $\logistic(y_k)$ where
    $y_k$ is the $y$ that has been observed. To ensure that the proposed method
    has the correct propensity score we use the oracle probabilities instead of
    estimating them. This yields the following:

    \input{Tables/nonmonosim3c0.tex}
    \input{Tables/nonmonosim3c0.1.tex}
    \input{Tables/nonmonosim3c0.5.tex}

    \newpage

    Thus, the proposed method is unbiased with a misspecified outcome model.
    We now show a simulation where the outcome model is correctly specified but
    the response model is not.

  \item \textbf{Simulation 4 with Nonmonotone MAR}:
    Continuing to test if the proposed algorithm is doubly robust, this
    simulation checks a misspecified response model. Instead of using oracle
    weights as in Simulation 3, we estimate the weights for the proposed method.
    The algorithms to which we compare still use the oracle weights.

    \input{Tables/nonmonosim4c0.tex}
    \input{Tables/nonmonosim4c0.1.tex}
    \input{Tables/nonmonosim4c0.5.tex}

    Thus, there is strong evidence that the proposed method is \textit{not}
    doubly robust. If we have a misspecified response model, then it seems like
    we induce bias. I will explore this more in the next section.

\end{itemize}

\newpage

\section*{Estimating the Response Model}

\begin{itemize}
  \item In most (critically \textit{not} Simulation 4) of the simulations of the
    previous section, we used the oracle weights when estimating our proposed
    method. The reasoning for this was straightforward{--}we wanted to ensure
    that the response model was correctly specified and the best case scenario
    is to use the oracle weights which we did.
    
  \item This section focuses more on estimating these response weights. Instead
    of focusing on the proposed method, we will actually be working on
    estimation of the complete case IPW estimator. This model is less complex
    and will thus make it easier to understand where we are making mistakes.

  \item We use the following simulation study:
    \begin{align*}
      x_i &\stackrel{iid}{\sim} N(0, 1)\\
      \varepsilon_{1i} &\stackrel{iid}{\sim} N(0, 1)\\
      \varepsilon_{2i} &\stackrel{iid}{\sim} N(0, 1)\\
      y_{1i} &= x_i + \varepsilon_{1i} \\
      y_{2i} &= x_i + \varepsilon_{2i} \\
    \end{align*}

    To select a missingness pattern for each $i$, we have sequence: first, we
    select the first variable to observe (or neither), then we either select the
    second variable or we do not. In the first step, we select $R_{1i} = 1$ with
    probability $0.4$, $R_{2i} = 1$ with probability $0.4$ and neither variable
    with probability $0.2$. For the second step, we have the probability of
    observing the other variable be $\logistic(x_i)$. This yields the following:

    \input{Tables/ipwsim.tex}
    % TODO: estimate IPW with \pi_{2|1} and \pi_{1|2}.

    The problem with this is that our estimate is biased. For one particular
    realization of the simulation, here is the distribution of the difference
    between the estimated and true probabilities of $\pi_{11}$:

    \includegraphics[width = 0.7\linewidth]{diffhist.png}
  
\end{itemize}

\newpage

\section*{Proposal: Full Nonmonotone Estimator}

\begin{itemize}

  \item When constructing
    estimates of the response model, we estimate $\pi_{11}$ using
    $\pi_{A_2 = 1|A_1 = 1}$ and we never include information about $\pi_{A_1 =
    1|A_2 = 1}$. I would like to create a full estimator where we are able to
    use this information.

  \item The current estimator is the following (See Slide 24 of Non-monotone
    Presentation):

    \begin{align*}
      \hat \theta_{eff} &= n^{-1} \sum_{i = 1}^n E[g_i \mid X_i] \\
      &+ n^{-1} \sum_{i = 1}^n \frac{R_{1i}}{\pi_{1+}(X_i)} (b_2(X_i, Y_{1i}) - 
      E[g_i \mid X_i]) \\
      &+ n^{-1} \sum_{i = 1}^n \frac{R_{2i}}{\pi_{2+}(X_i)} (a_2(X_i, Y_{2i}) -
      E[g_i \mid X_i]) \\
      &+ n^{-1} \sum_{i = 1}^n \frac{R_{1i} R_{2i}}{\pi_{11}(X_1, Y_{1i})}(g_i 
      - b_2(X_i, Y_{1i}) - a_2(X_i, Y_{2i}) + E[g_i \mid X_i])
    \end{align*}

  \item The problem with this is that we assume $\pi_{11}(X, Y_{1}) =
    \pi_{2|1} (X, Y_{1}) \pi_{1+}(X)$ when we could have $\pi_{11}(X, Y_2) =
    \pi_{1|2} (X, Y_2) \pi_{2+}(X)$. In other words, the previous result
    implicitly assumes that $\pi_{11}$ is a function of $X$ and $Y_1$ when it
    could be a function of $X$ and $Y_2$ as well. 

  \item I think that we could use the
    following (small modification) instead,

    \[\pi_{11}(X, Y_1, Y_2) = \alpha \pi_{1|2} \pi_{2+} + (1 - \alpha) \pi_{2|1}
    \pi_{1+}\]

    for some $\alpha \in [0, 1]$.
    
  \item The reasoning behind this is two-fold. First, it allows us to think of
    the nonmonotone missingness case as a linear combination of two monotone
    cases, which I think is useful. Second, we can make explicit our choice of
    $\alpha$, which in the existing estimator is simply $\alpha = 0$.

  \item The problem with adding another parameter $\alpha$ is that it makes the
    overall model unidentifiable. We cannot estimate $\alpha$ and the
    conditional and marginal distributions that we have without additional
    assumptions. So for now, I think that we should just assume that $\alpha$ is
    known and then we apply this method to a data integration problem we can
    review what $\alpha$ makes sense or figure out an additional assumption that
    can help us estimate $\alpha$ (for example if there is a variable correlated
    with $1|2$ versus $2|1$).

  \item This is not just a pure Bayes' rule.
    Formally, let $L = (X, Y_1, Y_2)$. By Bayes' rule we have

    \begin{align*}
      \Pr(R_1 &= 1 \mid R_2 = 1, L) \Pr(R_2 = 1 \mid L) \\
      &= \Pr(R_1 = 1, R_2 = 1 \mid L) \\
      & = \Pr(R_2 = 1 \mid R_1 = 1, L) \Pr(R_1 = 1 \mid L).
    \end{align*}

    Yet to estimate this model, we need to assume something like the following:
    \begin{align*}
      \Pr(R_1 &= 1 \mid R_2 = 1, X, Y_2) \Pr(R_2 = 1 \mid X, Y_2)\\
      &= \Pr(R_1 = 1, R_2 = 1 \mid L) \\
      &= \Pr(R_2 = 1 \mid R_1 = 1, X, Y_1) \Pr(R_1 = 1 \mid X, Y_1)
    \end{align*}

    in which case the two sides are clearly different.

    \item Unfortunately, early simulation results are not promising because we
      cannot distinguish points that should have $\pi_{11}$ conditional on $Y_1$
      and points that should be conditional on $Y_2$.

      \input{Tables/alphasim.tex}

    \item Dr. Kim, please let me know what you think about this idea and if it
      is worth pursuing more.

\end{itemize}

\newpage

\printbibliography

\end{document}

